cacheSolve(a)
cacheSolve(a)
cacheSolve(a)
zz<-matrix(rnorm(25,10), nrow=10)
zz<-matrix(rnorm(25,10), nrow=25)
zz
zz<-matrix(rnorm(26,10), nrow=13, ncol=2)
a<-makeCacheMatrix(zz)
cacheSolve(a)
q
?subset
data(mtcars)
head(mtcars)
mtcars[mtcars$cyl=6]
mtcars[mtcars$cyl="6"]
mtcars[mtcars$cyl]
mtcars[cyl]
mtcars["cyl"]
mtcars["cyl"=4]
mtcars[,mtcars$cyl="6"]
mtcars[mtcars$cyl == 3,]
mtcars[mtcars$cyl == 4,]
find.packages("plyr")
library(plyr)
fileUrl <- (http://data.baltimorecity.gov/api/views/k5ry-ef3g/rows.csv?accessType=DOWNLOAD)
fileUrl <- ("http://data.baltimorecity.gov/api/views/k5ry-ef3g/rows.csv?accessType=DOWNLOAD")
download.file(fileUrl, destfile="rest.csv")
restData<-read.csv("rest.csv")
View(restData)
View(restData)
head(restData)
tail(restData)
summary(restData)
?str
str(restData)
qualtile(restData$councilDistrict, na.rm=TRUE)
quantile(restData$councilDistrict, na.rm=TRUE)
quantile(restData$councilDistrict, na.rm=TRUE, probs=c(0.5,0.75,0.9))
library(datasets)
data(UCBAdmissions)
DF=as.data.frame(UCBAdmissions)
summary(DF)
View(DF)
xt <- xtabs(Freq Ëœ Gender + Admit, data=DF)
xt <- xtabs(Freq ~ Gender + Admit, data=DF)
xt
restData$nearMe = restData$neighborhood %in% c("Roland Park", "Homeland")
head(restData, n=3)
table(restData)
table(restData$nearMe)
library(Hmisc)
install.packages("Hmisc")
libraty(Hmisc)
library(Hmisc)
yesno <- sample(c("yes", "no"), size=10, replace=TRUE)
yesno
yesnofac <- factor(yesno, levels=c("yes", "no"))
yesnofac
as.numeric(yesnofac)
relevel(yesnofac, ref="no")
as.numeric(yesnofac)
yesnofac=relevel(yesnofac, ref="no")
as.numeric(yesnofac)
library(reshape2)
head(mtcars)
?melt
mtcars$carname <- rownames(mtcars)
head(mtcars, n=3)
carMelt <- melt(mtcars, id=c("carname", "gear", "cyl"), measure.vars=c("mpg", "hp"))
head(carMelt, n=3)
tail(carMelt, n=3)
View(carMelt)
?dcast
cylData <- dcast(carMelt, cyl~variable)
cylData
cylData <- dcast(carMelt, cyl~variable, mean)
cylData
cylData <- dcast(carMelt, cyl~variable, mean, range)
cylData <- dcast(carMelt, cyl~variable, range)
cylData <- dcast(carMelt, cyl~variable, min)
cylData <- dcast(carMelt, cyl~variable, sd)
cylData
fileUrl1 <- "http://dl.dropboxsecurecontent.com/u/7710864/data/reviews-apr29.csv"
fileUrl2 <- "http://dl.dropboxsecurecontent.com/u/7710864/data/aolutions-apr29.csv"
download.file(fileUrl1, destfile="reviews.csv")
download.file(fileUrl2, destfile="solutions.csv")
reviews = read.csv("reviews.csv"); solutions = read.csv("solutions.csv")
reviews = read.csv("reviews.csv")
fileUrl1 <- "https://dl.dropboxsecurecontent.com/u/7710864/data/reviews-apr29.csv"
fileUrl2 <- "https://dl.dropboxsecurecontent.com/u/7710864/data/aolutions-apr29.csv"
download.file(fileUrl1, destfile="reviews.csv")
download.file(fileUrl1, destfile="reviews.csv", method=curl)
download.file(fileUrl1, destfile="reviews.csv", method="curl")
download.file(fileUrl1, destfile="reviews.csv", method="lynx")
download.file(fileUrl1, destfile="reviews.csv", method="wget")
fileUrl1
fileUrl1 <- "http://dl.dropboxusercontent.com/u/7710864/data/reviews-apr29.csv"
fileUrl2 <- "http://dl.dropboxusercontent.com/u/7710864/data/aolutions-apr29.csv"
download.file(fileUrl1, destfile="reviews.csv", method="wget")
download.file(fileUrl1, destfile="reviews.csv")
download.file(fileUrl2, destfile="solutions.csv")
fileUrl2 <- "http://dl.dropboxusercontent.com/u/7710864/data/solutions-apr29.csv"
download.file(fileUrl2, destfile="solutions.csv")
reviews = read.csv("reviews.csv")
solutions = read.csv("solutions.csv")
head(reviews, n=2)
head(solution, n=2)
head(solutions, n=2)
mergedData <- merge(solution, reviews,by.x="solution_id",by.y="id",all=TRUE)
mergedData <- merge(solutions, reviews,by.x="solution_id",by.y="id",all=TRUE)
mergedData <- merge(solutions, reviews, by.x="solution_id", by.y="id",all=TRUE)
mergedData <- merge(reviews, solutions, by.x="solution_id", by.y="id",all=TRUE)
head(mergedData)
length(mergedData)
dims(mergedData)
dim(mergedData)
nrows(mergedData)
nrow(mergedData)
fileUrl = "http://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06hid.csv"
download.file(fileUrl, destfile="acs2006.csv")
acs=read.csv("acs2006.csv")
rm(mtcars, carMelt, cylData, mergedData, reviews, solutions)
?wichi
?which
agricultureLogical <- acs[(acs$ACR==3 & acs$AGR == 6),]
acs[(acs$ACR==3 & acs$AGR == 6),]
acs[(acs$ACR==3 & acs$AGS == 6),]
agricultureLogical <- acs[(acs$ACR==3 & acs$AGS == 6),]
which(agricultureLogical)
agricultureLogical <- ifelse((acs$ACR==3 & acs$AGS == 6), TRUE, FALSE)
which(agricultureLogical)
View(acs)
install.packages("jpeg")
library(jpeg)
jpegUrl <- "https://d396qusza40orc.cloudfront.net/getdata%2Fjeff.jpg"
jpegREAD(jpegUrl)
readJPEG(jpegUrl)
jpegUrl <- "http://d396qusza40orc.cloudfront.net/getdata%2Fjeff.jpg"
download.file(jpegUrl, destfile="jeff.jpg")
readJPEG("jeff.jpg")
readJPEG("jeff.jpg", native=TRUE)
quantile(readJPEG("jeff.jpg", native=TRUE), probs=c(0.3,0.8))
quantile(readJPEG("jeff.jpg", native=TRUE), probs=c(0.2,0.8))
jpg <- readJPEG("jeff.jpg", native=TRUE)
readJPEG("jeff.jpg", native=TRUE)
readJPEG("jeff.jpg")
jpg <- readJPEG("jeff.jpg", native=TRUE)
quantile(jpg, probs=c(0.3,0.8))
download.file(jpegUrl, destfile="jeff.jpg", mode="wb")
jpg <- readJPEG("jeff.jpg", native=TRUE)
quantile(jpg, probs=c(0.3,0.8))
gdpUrl <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FGDP.csv"
gdpUrl <- "http://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FGDP.csv"
download.file(gdpUrl, destfile="gdp.csv")
eduUrl <- "http://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FEDSTATS_Country.csv"
download.file(eduUrl, destfile="edu.csv")
read.csv("edu.csv") -> edu
read.csv("gdp.csv") -> gdp
head(edu, n=4)
head(gdp, n=4)
View(gdp)
View(edu)
gdp <- gdp[1:194,]
View(gdp)
gdp <- gdp[5:194,]
View(gdp)
View(gdp)
gdpedu <- merge(gdp, edu, by.x="X", by.y="CountryCode", all=TRUE)
View(gdpedu)
!is.na(gdpedu$X.2)
is.na(gdpedu$X.2)
sum(is.na(gdpedu$X.2))
sum(!is.na(gdpedu$X.2))
sort <- sort(gdpedu$X.3, decreasing=TRUE)
sort
rm(sort, eduUrl, fileUrl, fileUrl1, fileUrl2, gdpUrl, jpegUrl, jpg)
gdpedu[order(gdpedu$X.3),]
sort <- gdpedu[order(gdpedu$X.3),]
library(plyr)
sort2 <- arrange(gdpedu, desc(X.3))
sort[13,]
sort[13,1]
sort[13,2]
View(sort)
View(sort2)
sort <- gdpedu[order(gdpedu$Gross.domestic.product.2012),]
sort2 <- arrange(gdpedu, desc(Gross.domestic.product))
sort2 <- arrange(gdpedu, desc(Gross.domestic.product.2012))
View(sort)
sort3 <- sort(gdpedu$Gross.domestic.product.2012, decreasing = TRUE)
sort3
View(sort2)
sort2 <- arrange(gdpedu, Gross.domestic.product.2012)
sort2[13]
sort2[13,1:10]
View(sort2)
average()
ave()
?ave
gdpedu$X.3[gdpedu$IncomeGroup=="High income: nonOECD",]
gdpedu[gdpedu$Income.Group=="High income: nonOECD",]
gdpedu$X.3[gdpedu$Income.Group=="High income: nonOECD",]
nonOECD <- gdpedu[gdpedu$Income.Group=="High income: nonOECD",]
mean(nonOECD$X.3)
mean(as.numeric(nonOECD$X.3))
mean(as.numeric(nonOECD$X.3), na.rm=TRUE)
mean(as.numeric(as.character(nonOECD$X.3))
}
gdpedu$Gross.domestic.product.2012 <- as.numeric(gdpedu$Gross.domestic.product.2012)
mean(gdpedu$Gross.domestic.product.2012)
mean(gdpedu$Gross.domestic.product.2012, na.rm=TRUE)
gdpedu$X.3 <- as.numeric(gdpedu$X.3)
mean(gdpedu$X.3, na.rm=TRUE)
View(gdpedu)
tapply(gdpedu$X.3, gdpedu$Income.Group, mean, na.rm=TRUE)
a<- tapply(gdpedu$X.3, gdpedu$Income.Group, mean, na.rm=TRUE)
a
gdpedu <- merge(gdp, edu, by.x="X", by.y="CountryCode", all=TRUE)
a<- tapply(gdpedu$X.3, gdpedu$Income.Group, mean, na.rm=TRUE)
View(gdpedu)
a
mean(gdpedu[which(gdpedu$Income.Group=="High income: OECD"),]$X.3, na.rm=TRUE)
names(gdpedu)
a<-names(gdpedu)
a[2]
a[2]<-"GDPR"
a
a[2]
gdpedut<-gdpedu
gdpedut <- names(a)
gdpedut
gdpedut <- names(a)
gdpedut<-gdpedu
?colnames
colnames(gdpedut) <- a
names(gdpedut)
colnames(gdpedu) <- a
View(gdpedu)
tapply(gdpedu$GDPR, gdpedu$Income.Group, mean, na.rm=TRUE)
class(gdpedu$GDPR)
gdpedu$GDPR <- as.numeric(gdpedu$GDPR)
class(gdpedu$GDPR)
tapply(gdpedu$GDPR, gdpedu$Income.Group, mean, na.rm=TRUE)
gdpedu <- gdpedu[order(gdpedu$GDPR),]
View(gdpedu)
gdpedu <- arrange(gdpedu, decs(GDPR))
gdpedu <- arrange(gdpedu, desc(GDPR))
View(gdpedu)
gdpedu <- gdpedu[1:190,]
View(gdpedu)
gdpedu[13,1]
mean(gdpedu$GDPR)
rm(gdpedu, gdpedut, nonOECD, sort, sort2)
rm(acs)
View(gdp)
head(gdp, n*1)
head(gdp, n=2)
gdp <- gdp[,2:10]
View(gdp)
gdp = read.csv("gdp.csv")
View(gdp)
gdp = gdp[5:194,]
View(gdp)
colnames(gdp$Gross.domestic.product.2012) <- "GDPR"
a <- colnames(gdp)
gdp <- [,1:5]
gdp <- gdp[,1:5]
View(gdp)
a <- colnames(gdp)
a[2]<-"GDPR"
colnames(gdp) <- a
View(gdp)
gdp <- as.numeric(gdp$GDPR)
gdp = read.csv("gdp.csv")
gdp = gdp[5:194,]
gdp <- [,1:5]
gdp <- gdp[,1:5]
colnames(gdp) <- a
View(gdp)
gdp$GDPR <- as.numeric(gdp$GDPR)
View(edu)
data <- merge(gdp, edu, by.x="X", by.y="CountryCode", all=TRUE)
View(data)
data1 <- data
reserve <- data
data <- arrange(data, desc(GDPR))
data[13,]
data[13,1]
data <- arrange(data, GDPR)
data[13,1]
View(data)
View(reserve)
tapply(data$GDPR, data$Income.Group, mean, na.rm=TRUE)
data <- merge(gdp, edu, by.x="X", by.y="CountryCode", all=FALSE)
View(data)
data1 <- arrange(data, desc(GDPR))
data2 <- arrange(data, GDPR)
data1[13,1]
data2[13,1]
View(data)
View(data1)
View(data2)
tapply(data$GDPR, data$Income.Group, mean, na.rm=TRUE)
tapply(data1$GDPR, data1$Income.Group, mean, na.rm=TRUE)
View(reserve)
tapply(data1$GDPR, data1$Income.Group, mean)
View(data)
class(data$GDPR)
class(gdp$GDPR)
View(data1)
View(data2)
gdp2 <- gdp[1:2,]
View(gdp2)
gdp2 <- gdp[,1:2]
View(gdp2)
gdp[1,2]
gdp2[1,2]
View(gdp)
View(gdp)
View(gdp)
gdp = read.csv("gdp.csv")
View(gdp)
gdp <- gdp[5:194,1:2]
View(gdp)
gdp = read.csv("gdp.csv")
gdp <- gdp[5:194,]
View(gdp)
colnames(gdp) -> a
a[2] <- GDPR
a[2] <- "GDPR"
colnames(gdp) <- a
View(gdp)
gdp[1,2]
gdp2 <- gdp
gdp2$GDRP <- as.numeric(gdp$GDRP)
gdp2$GDRP <- as.numeric(gdp2$GDRP)
gdp2$GDPR <- as.numeric(gdp2$GDRP)
gdp2$GDPR <- as.numeric(gdp2$GDPR)
View(gdp2)
rm(agricultureLogical)
rm(sort3)
gdp2$GDPR <- as.character(gdp2$GDPR)
gdp2$GDPR <- as.character(gdp$GDPR)
View(gdp2)
gdp2$GDPR <- as.numeric(gdp2$GDPR)
View(gdp2)
data <- merge(gdp, edu, by.x="X", by.y="CountryCode", all=FALSE)
rm(data1, data2, reserve)
data <- merge(gdp2, edu, by.x="X", by.y="CountryCode", all=FALSE)
View(data)
gdp <- gdp2, rm(gdp2)
gdp <- gdp2: rm(gdp2)
gdp <- gdp2; rm(gdp2)
View(gdp)
sort <- arrange(data, desc(GDPR))
sort [13,1]
sort1 <- arrange(data, GDPR)
sort [13,1]
View(sort)
View(sort1)
sort1 [13,1]
tapply(data$GDPR, data$Income.Group, mean)
data1 <- data
data1$GDPRGroup <- cut(data1$GDPR, breaks=quantile(data1$GDPR))
table(data1$GDPRGroup)
quantile(data1$GDPR, n=5)
?quantile
library(Hmisc)
data1$GDPRGroup <- cut2(data1$GDPR, g=5)
table(data1$GDPRGroup)
table(data1$GDPRGroup, data1$Income.Group)
a5<-table(data1$GDPRGroup, data1$Income.Group)
as.data.frame(a5)
a5<-as.data.frame(a5)
View(`a5`)
str(str)
str(lm)
str(data)
str(a5)
summary(a5)
str(airquality)
summary(airquality)
cameraData<-read.csv("cameras.csv")
names(cameraData)
View(cameraData)
reviews<-read.csv("reviews.csv"); solutions<-("solutions.csv")
reviews<-read.csv("reviews.csv"); solutions<-read.csv("solutions.csv")
x=c("1jan1960","31mar1960")
z<-as.Date(x, "%d%b%Y")
z
z[1]-z[2]
install.packages("lubridate")
library(lubridate)
acs<-read.csv("acs2006.csv")
names <- strsplit(names(acs))
names(acs)
strsplit
names <- strsplit(names(acs),)
names <- strsplit(names(acs),"wgtp")
names[123]
gdp<-read.csv("gdp.csv")
names(gdp)
head(gdp)
dim(gdp)
gdp<-gdp[5:330,]
head(gdp)
gsub(",","",gdp)
gsub(",","",gdp[,5])
gdp[,5]<-gsub(",","",gdp[,5])
mean(gdp[,5])
gdp[,5]<-as.numeric(gdp[,5])
mean(gdp[,5])
mean(gdp[,5],na.rm=T)
View(gdp)
gdp<-gdp[1:190,]
mean(gdp[,5],na.rm=T)
grep("^United", X.2)
grep("^United", gdp$X.2)
edu<-read.csv("edu.csv")
head(edu)
View(edu)
gdpedu <- merge(gdp,edu,by.x="X",by.y="CountryCode",all=FALSE)
View(gdpedu)
table(grepl("Fiscal year end: June",gdpedu$Special.Notes))
install.packages("quantmode")
install.packages("quantmod")
library(quantmod)
amzn = getSymbols("AMZN", auto.assign=FALSE)
View(amzn)
sampleTimes = index(amzn)
amznDF <-as.data.frame(amzn)
sampleTimes = index(amznDF)
head(sampleTimes)
sampleTimes = index(amzn)
sampleTimes
table(grepl("2012",sampleTimes))
q52<-sampleTimes[grepl("2012",sampleTimes)]
length(q52)
table(grepl("Monday",weekdays(q52)))
fileUrl<-"http://biostat.jhsph.edu/~jleek/contact.html"
download.file(fileUrl, "text.txt")
?htmlparse
?parse
html<-htmlTreeParse(text.txt, useInternalNodes=T)
libraty(XML)
library(XML)
html<-htmlTreeParse(text.txt, useInternalNodes=T)
html<-htmlTreeParse("text.txt", useInternalNodes=T)
head(html)
readlines(html)
readLines(html)
readLines("http://biostat.jhsph.edu/~jleek/contact.html")
html <- readLines("http://biostat.jhsph.edu/~jleek/contact.html")
nchar <-html[c(10,20,30,100)]
nchar(nchar)
setwd("L:/R/Work")
source("first_analysis.R")
q95 <- quantile(post$Engagements, 0.95)
q95
post <- subset(post, post$Engagement < q95)
## this code is created to produce an analysis of downloaded data from VK ##
## to run this correctly, the filename should ALWAYS be 'posts.csv'       ##
## reading the file
post<-read.csv("posts.csv", header=TRUE, na.strings="")
## removing unneeded colums, like 'Type', 'Clear_eng', 'Delay'
post[c(2:7,17:19)]<-list(NULL)
## preparing the names
names<-c("Date", "Commenters", "Comments", "Admin_commetns", "Agent_comments", "Shares", "Likes", "Votes", "Active_users", "Engagements", "Reach")
## setting proper names
colnames(post)<-names
## removing NAs with 0
post[is.na(post)] <- 0
## performing operations with dates and times to obtain additional data
post$Time <- as.POSIXct(strftime(post$Date, format="%H:%M:%S"), format="%H:%M:%S")
post$Date <- as.POSIXct(strptime(post$Date, format="%Y-%m-%d %H:%M:%S"))
## obtaining the weekdays
weekday<-as.factor(weekdays(post$Date))
levels(weekday) <- c("Monday", "Tuesday", "Wednesday", "Thursday", "Friday", "Saturday", "Sunday")
post$Weekday<-weekday
## cleaning the data
q95 <- quantile(post$Engagements, 0.95)
post <- subset(post, post$Engagement < q95)
?input
??input
source('~/.active-rstudio-document')
source('~/.active-rstudio-document')
clean
clean()
clean <- function (q) {
q<-readline("Which quantile should limit the data? (use decimals) ")
setq <- quantile(post$Engagements, q)
post <- subset(post, post$Engagement < setq)
}
clean()
q<-readline("Which quantile should limit the data? (use decimals) ")
class(q)
q<-as.numeric(readline("Which quantile should limit the data? (use decimals) "))
q
class(q)
clean <- function (q) {
q<-as.numeric(readline("Which quantile should limit the data? (use decimals) "))
setq <- quantile(post$Engagements, q)
post <- subset(post, post$Engagement < setq)
}
clean()
clean()
setq <- quantile(post$Engagements, q)
q<-as.numeric(readline("Which quantile should limit the data? (use decimals) "))
setq <- quantile(post$Engagements, q)
post <- subset(post, post$Engagement < setq)
source('~/.active-rstudio-document')
source('~/.active-rstudio-document')
